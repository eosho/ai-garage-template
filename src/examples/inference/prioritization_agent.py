# prioritization_agent.py

"""Hazard Prioritization Agent"""

import asyncio
import json
import argparse

from typing import Dict, Any
from azure.ai.inference.models import JsonSchemaFormat

from hazard_agent.schemas import HazardPrioritizationOutput
from factory.llm.factory import LLMFactory
from hazard_agent.prompts.prompts import HAZARD_PRIORITIZATION_PROMPT
from factory.logger.telemetry import LoggingFactory

# Initialize telemetry (Azure Monitor if configured, otherwise fallback to console)
logging_factory = LoggingFactory()

# Get a logger and tracer
logger = logging_factory.get_logger(__name__)
tracer = logging_factory.get_tracer(__name__)


class HazardPrioritizationAgent:
    """Agent wrapper for hazard prioritization using an LLM provider."""

    def __init__(self, provider):
        """
        Initialize the hazard prioritization agent.

        Args:
            provider: An instance of an LLMProviderBase subclass (e.g., AzureInferenceProvider).
        """
        self.provider = provider

    @staticmethod
    def get_schema() -> Dict[str, Any]:
        """Return the strict JSON schema for hazard prioritization output."""
        return HazardPrioritizationOutput.model_json_schema()

    async def analyze(self, query: str) -> str:
        """
        Analyze a query with the hazard prioritization schema.

        Args:
            query (str): User query to guide hazard prioritization.

        Returns:
            str: Strict JSON response containing hazard prioritization.
        """
        logger.info("Submitting hazard prioritization request for query=%s", query)

        response = await self.provider.get_completion(
            system_prompt=HAZARD_PRIORITIZATION_PROMPT,
            user_prompt=query,
            max_tokens=1500,
            response_format=JsonSchemaFormat(
                name="hazard_prioritization_schema",
                schema=self.get_schema(),
                description="Schema for prioritizing hazards",
                strict=True,
            ),
            return_usage=True,
        )

        logger.info("Hazard prioritization completed.")
        json_str, usage = response

        # Parse the JSON string nicely
        parsed = json.dumps(json.loads(json_str), indent=2)
        logger.debug("Parsed response: %s", parsed)

        # Only if return_usage=True
        logger.info("Token usage: %s", json.dumps(usage, indent=2))

        return parsed


async def main(query: str):
    # Create the provider via factory
    provider = await LLMFactory.create_llm_provider()

    # Pass provider directly into the agent
    agent = HazardPrioritizationAgent(provider=provider)
    output = await agent.analyze(query=query)

    logger.info("Hazard Detection Result: %s", output)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Run hazard prioritization analysis with a given query."
    )
    parser.add_argument(
        "--query",
        type=str,
        default="""Here is what was generated by the hazard identification agent:
{
  "hazards_detected": true,
  "hazard_count": 3,
  "hazards": [
    {
      "id": "1",
      "type": "ppe_violation",
      "description": "Hard hat on the floor and not being worn.",
      "severity": "high",
      "location": "warehouse floor",
      "recommendations": "Ensure all workers wear appropriate PPE, including hard hats, at all times."
    },
    {
      "id": "2",
      "type": "floor_safety",
      "description": "Hard hat left on the floor poses a tripping hazard.",
      "severity": "medium",
      "location": "warehouse floor",
      "recommendations": "Remove the hard hat from the floor to eliminate the tripping hazard."
    },
    {
      "id": "3",
      "type": "working_at_heights",
      "description": "Unsecured ladder placed in the aisle.",
      "severity": "high",
      "location": "aisle near shelves",
      "recommendations": "Secure ladders properly and ensure they are used safely according to workplace guidelines."
    }
  ]
}
""",
        help="The hazard identification result JSON or description to analyze.",
    )
    args = parser.parse_args()

    asyncio.run(main(args.query))
